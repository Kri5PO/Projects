{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LGBMClassifier</a></span></li><li><span><a href=\"#RidgeClassifier\" data-toc-modified-id=\"RidgeClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>RidgeClassifier</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>BERT</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Общий вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\79853\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\79853\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\79853\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\79853\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\79853\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# загрузка библиотек\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import transformers\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from lightgbm import LGBMClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение файла с данными и сохранение в переменную df\n",
    "try:\n",
    "    df = pd.read_csv('C:/Users/79853/Documents/datascience/yandex/Спринт14/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv') # загрузка онлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>159571.0</td>\n",
       "      <td>0.101679</td>\n",
       "      <td>0.302226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std  min  25%  50%  75%  max\n",
       "toxic  159571.0  0.101679  0.302226  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11\u001b[0;0m\n",
      "bbq \n",
      "\n",
      "be a man and lets discuss it-maybe over the phone?\n",
      "\n",
      "\u001b[1m12\u001b[0;0m\n",
      "Hey... what is it..\n",
      "@ | talk .\n",
      "What is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\n",
      "\n",
      "Ask Sityush to clean up his behavior than issue me nonsensical warnings...\n",
      "\n",
      "\u001b[1m13\u001b[0;0m\n",
      "Before you start throwing accusations and warnings at me, lets review the edit itself-making ad hominem attacks isn't going to strengthen your argument, it will merely make it look like you are abusing your power as an admin. \n",
      "Now, the edit itself is relevant-this is probably the single most talked about event int he news as of late. His absence is notable, since he is the only living ex-president who did not attend. That's certainly more notable than his dedicating an aircracft carrier. \n",
      "I intend to revert this edit, in hopes of attracting the attention of an admin that is willing to look at the issue itself, and not throw accusations around quite so liberally. Perhaps, if you achieve a level of civility where you can do this, we can have a rational discussion on the topic and resolve the matter peacefully.\n",
      "\n",
      "\u001b[1m14\u001b[0;0m\n",
      "Oh, and the girl above started her arguments with me. She stuck her nose where it doesn't belong. I believe the argument was between me and Yvesnimmo. But like I said, the situation was settled and I apologized. Thanks,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(11, 15):\n",
    "    print(\"\\033[1m\" + str(i) + \"\\033[0;0m\")\n",
    "    print(df['text'][i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Признаки:**\n",
    "- **text** — текст комментария, \n",
    "- **toxic** — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    89.832112\n",
       "1    10.167888\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# процентное соотношение значений 0 и 1 в целевом признаке\n",
    "df['toxic'].value_counts()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подсчёт явных дубликатов\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст комментариев на английском языке. Соотношение токсичных комментариев к нетоксичным 1:9. При обучении моделей можно использовать гиперпараметр для борьбы с дисбалансом классов.\n",
    "\n",
    "В данных нет пропусков и дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# очистка текста от цифр, несловесных и одиночных символов и т.д.\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\d\", \"\", text)               # удаление цифр\n",
    "    text = re.sub(r\"\\W\", \" \", text, flags=re.I)  # удаление всех несловесных символов     \n",
    "    text = re.sub(r\"\\s+[a-z]\\s+\", \" \", text)     # удаление одиночных символов\n",
    "    text = re.sub(r\"_\", \" \", text)               # удаление знака подчеркивания\n",
    "    text = re.sub(r\"\\s+\",\" \", text, flags=re.I)  # удаление нескольких пробелов\n",
    "    text = re.sub(r\"^\\s\", \"\", text)              # удаление пробелов из начала строки\n",
    "    text = re.sub(r\"\\s+$\", \"\", text)             # удаление пробелов с конца строки\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# лемматизация текста\n",
    "def lemma(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    for words in tokens:\n",
    "        lemmatizer.lemmatize(words)\n",
    "        \n",
    "    tagged = nltk.pos_tag(tokens)  # таггетированный текст\n",
    "    \n",
    "    # удаление из текста предлогов, союзов, частиц и др.\n",
    "    tokens_clean = []\n",
    "    words_del = ['CC', 'DT', 'EX', 'IN', 'RP', 'SYM', 'TO', 'FW']\n",
    "    \"\"\"\n",
    "        CC - Coordinating conjunction\n",
    "        DT - Determiner\n",
    "        EX - Existential there\n",
    "        IN - Preposition or subordinating conjunction\n",
    "        RP - Particle\n",
    "        SYM - Symbol\n",
    "        TO - to\n",
    "        FW - Foreign word\n",
    "    \"\"\"\n",
    "    for i in range(len(tokens)):\n",
    "        if tagged[i][1] not in words_del:\n",
    "            tokens_clean.append(tokens[i])\n",
    "        \n",
    "    return tokens_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подготовки датасета, разбиение на train, test и features, target\n",
    "\n",
    "def prepare_data(data, sample_size, test_size, target, text):\n",
    "    \n",
    "    # формирование подвыборки из датасета\n",
    "    data = data.sample(sample_size).reset_index(drop=True)\n",
    "    \n",
    "    data[text] = data[text].transform(lambda x: clean_text(x))  # очистка текста\n",
    "    data[text] = data[text].transform(lambda x: lemma(x))       # лемматизация текста\n",
    "    \n",
    "    # обрезка строк по средней длине строки\n",
    "    df['text_len'] = df[text].transform(lambda x: len(x))\n",
    "    mean_len = int(df['text_len'].mean())\n",
    "    df[text] = df.text.str[:mean_len]\n",
    "    \n",
    "    data[text] = data[text].transform(lambda x: ' '.join(x))\n",
    "    \n",
    "    # разбиваем датасет на тренировочную и тестовую выборку\n",
    "    train, test = train_test_split(data, test_size=test_size, random_state=123)\n",
    "    \n",
    "    train_features = train[text]\n",
    "    train_target = train[target]\n",
    "    test_features = test[text]\n",
    "    test_target = test[target]\n",
    "    \n",
    "    # получение TF-IDF для N-грамм корпуса текста\n",
    "    count_tf_idf = TfidfVectorizer(stop_words=stopwords, ngram_range=(1, 3), min_df=3, max_df=0.8, sublinear_tf=True)\n",
    "    \n",
    "    train_features = count_tf_idf.fit_transform(train_features)\n",
    "    test_features = count_tf_idf.transform(test_features)\n",
    "    \n",
    "    return train_features, train_target, test_features, test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем на кроссвалидации гиперпараметры для трех моделей:\n",
    "- LGBMClassifier(),\n",
    "- LogisticRegression(),\n",
    "- RidgeClassifier()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для определения гиперпараметров модели\n",
    "def grid_search(model, params):\n",
    "    grid_cv = GridSearchCV(estimator=model,\n",
    "                           param_grid=params,\n",
    "                           cv=4,\n",
    "                           n_jobs=-1,\n",
    "                           scoring='f1')\n",
    "    \n",
    "    start_fit_time = time.time()\n",
    "    grid_cv.fit(train_features, train_target)\n",
    "    crossval_time = time.time() - start_fit_time\n",
    "    \n",
    "    print('Гиперпараметры: ', grid_cv.best_params_)\n",
    "    \n",
    "    global a\n",
    "    columns = ['model_name', 'model', 'time_sec', 'F1', 'process']\n",
    "    rows = [['', model, round(crossval_time, 1), round(grid_cv.best_score_, 3), 'кроссвалидация']]\n",
    "    a = pd.DataFrame(data=rows, columns=columns)\n",
    "    \n",
    "    return grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>F1</th>\n",
       "      <th>process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, model, time_sec, F1, process]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# таблица для накопления результатов\n",
    "columns = ['model_name', 'model', 'time_sec', 'F1', 'process']\n",
    "result_tbl = pd.DataFrame(columns=columns)\n",
    "result_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения полей таблицы с результатами:\n",
    "- **model_name** – название модели,\n",
    "- **model** – конфигурация модели,\n",
    "- **time_sec** – время обучения/тестирования модели в секундах,\n",
    "- **F1** – метрика качества F1,\n",
    "- **process** - обучение/тестирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_features, train_target, test_features, test_target = prepare_data(df, sample_size=100000,\n",
    "                                                                        test_size=0.25,\n",
    "                                                                        target='toxic',\n",
    "                                                                        text='text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "192 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.76846425        nan 0.76967529 0.74206849\n",
      " 0.74278754 0.74206849 0.74206849 0.74195339        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.76717317\n",
      "        nan 0.77260568 0.76928055 0.76941399 0.76936326 0.76954745\n",
      " 0.7701854         nan        nan        nan        nan        nan\n",
      "        nan        nan 0.74468917        nan 0.74468917 0.64034059\n",
      " 0.64045233 0.64028466 0.64034059 0.64052012        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.75006559\n",
      "        nan 0.73445843 0.75519448 0.7552392  0.75514978 0.75519448\n",
      " 0.74871711        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.54808593        nan 0.54808769 0.2719873\n",
      " 0.2719873  0.27334117 0.2719873  0.2719873         nan        nan\n",
      "        nan        nan        nan        nan        nan 0.70508611\n",
      "        nan 0.70562577 0.71672468 0.71680868 0.71678221 0.71676746\n",
      " 0.71679968        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гиперпараметры:  {'C': 10, 'class_weight': 'balanced', 'n_jobs': -1, 'penalty': 'l1', 'random_state': 123, 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best1 = grid_search(LogisticRegression(), params={'class_weight': [None, 'balanced'],\n",
    "                                                  'C': [10, 1.0, 0.1],\n",
    "                                                  'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                                                  'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                                                  'random_state': [123],\n",
    "                                                  'n_jobs': [-1]\n",
    "                                                 })\n",
    "result_tbl = pd.concat([result_tbl, a], axis = 0) # добавление показателей в общую таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(**best1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гиперпараметры:  {'class_weight': None, 'learning_rate': 0.1, 'n_estimators': 300, 'n_jobs': -1, 'random_state': 123}\n"
     ]
    }
   ],
   "source": [
    "best = grid_search(LGBMClassifier(), params={'class_weight': [None, 'balanced'],\n",
    "                                             'learning_rate': [0.05, 0.1],\n",
    "                                             'n_estimators': [100, 300],\n",
    "                                             'random_state': [123],\n",
    "                                             'n_jobs': [-1]\n",
    "                                            })\n",
    "result_tbl = pd.concat([result_tbl, a], axis = 0) # добавление показателей в общую таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmclf = LGBMClassifier(**best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гиперпараметры:  {'alpha': 0.4, 'class_weight': None, 'fit_intercept': True, 'random_state': 123}\n"
     ]
    }
   ],
   "source": [
    "best2 = grid_search(RidgeClassifier(), params={'class_weight': [None, 'balanced'],\n",
    "                                               'alpha': [0.1, 0.4, 0.7, 1.0],\n",
    "                                               'fit_intercept': [True, False],\n",
    "                                               'random_state': [123]\n",
    "                                               })\n",
    "result_tbl = pd.concat([result_tbl, a], axis = 0) # добавление показателей в общую таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridclf = RidgeClassifier(**best2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>F1</th>\n",
       "      <th>process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.773</td>\n",
       "      <td>кроссвалидация</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>704.2</td>\n",
       "      <td>0.759</td>\n",
       "      <td>кроссвалидация</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>RidgeClassifier()</td>\n",
       "      <td>63.9</td>\n",
       "      <td>0.704</td>\n",
       "      <td>кроссвалидация</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name                 model  time_sec     F1         process\n",
       "0             LogisticRegression()     932.0  0.773  кроссвалидация\n",
       "0                 LGBMClassifier()     704.2  0.759  кроссвалидация\n",
       "0                RidgeClassifier()      63.9  0.704  кроссвалидация"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем модель логистической регрессии, у которой самое высокое значение метрики F1 на кроссвалидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для тестирования модели\n",
    "def test(model, name):\n",
    "    \n",
    "    start_fit_time = time.time()\n",
    "    model.fit(train_features, train_target)\n",
    "    fit_time = time.time() - start_fit_time\n",
    "    \n",
    "    predictions = model.predict(train_features)\n",
    "    \n",
    "    start_predict_time = time.time()\n",
    "    predictions2 = model.predict(test_features)\n",
    "    predict_time = time.time() - start_predict_time\n",
    "        \n",
    "    global a\n",
    "    columns = ['model_name', 'model', 'time_sec', 'F1', 'process']\n",
    "    rows = [[name, model, round(fit_time, 1), round(f1_score(train_target, predictions), 3), 'обучение'],\n",
    "            [name, model, round(predict_time, 1), round(f1_score(test_target, predictions2), 3), 'тестирование']]\n",
    "    a = pd.DataFrame(data=rows, columns=columns)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions = test(logreg, name='logreg')\n",
    "result_tbl = pd.concat([result_tbl, a], axis = 0) # добавление показателей в общую таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>F1</th>\n",
       "      <th>process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.773</td>\n",
       "      <td>кроссвалидация</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>704.2</td>\n",
       "      <td>0.759</td>\n",
       "      <td>кроссвалидация</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>RidgeClassifier()</td>\n",
       "      <td>63.9</td>\n",
       "      <td>0.704</td>\n",
       "      <td>кроссвалидация</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>LogisticRegression(C=10, class_weight='balance...</td>\n",
       "      <td>362.9</td>\n",
       "      <td>0.969</td>\n",
       "      <td>обучение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logreg</td>\n",
       "      <td>LogisticRegression(C=10, class_weight='balance...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>тестирование</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name                                              model  time_sec  \\\n",
       "0                                          LogisticRegression()     932.0   \n",
       "0                                              LGBMClassifier()     704.2   \n",
       "0                                             RidgeClassifier()      63.9   \n",
       "0     logreg  LogisticRegression(C=10, class_weight='balance...     362.9   \n",
       "1     logreg  LogisticRegression(C=10, class_weight='balance...       0.0   \n",
       "\n",
       "      F1         process  \n",
       "0  0.773  кроссвалидация  \n",
       "0  0.759  кроссвалидация  \n",
       "0  0.704  кроссвалидация  \n",
       "0  0.969        обучение  \n",
       "1  0.774    тестирование  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия показала лучшие результаты среди исследованных моделей, в ходе тестирования удалось достичь необходимого значения метрики качества F1 выше 0,75. \n",
    "\n",
    "Далее попробуем использовать нейронную сеть Bert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = df.sample(6000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (transformers.DistilBertModel,\n",
    "                                                    transformers.DistilBertTokenizer,\n",
    "                                                    'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df_bert['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(512 - len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e91ead676e4e208af66f82f8dd8c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "target = df_bert['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# индекс для отделения тестовой выборки\n",
    "test_index = int(len(df_bert)*(1-0.25))\n",
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features[:test_index]\n",
    "train_target = target[:test_index]\n",
    "\n",
    "test_features = features[test_index:]\n",
    "test_target = target[test_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_Bert = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79853\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "predictions3 = test(logistic_Bert, name='logistic_Bert')\n",
    "result_tbl = pd.concat([result_tbl, a], axis = 0) # добавление показателей в общую таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>F1</th>\n",
       "      <th>process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.773</td>\n",
       "      <td>кроссвалидация</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>704.2</td>\n",
       "      <td>0.759</td>\n",
       "      <td>кроссвалидация</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>RidgeClassifier()</td>\n",
       "      <td>63.9</td>\n",
       "      <td>0.704</td>\n",
       "      <td>кроссвалидация</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>LogisticRegression(C=10, class_weight='balance...</td>\n",
       "      <td>362.9</td>\n",
       "      <td>0.969</td>\n",
       "      <td>обучение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logreg</td>\n",
       "      <td>LogisticRegression(C=10, class_weight='balance...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>тестирование</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_Bert</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.824</td>\n",
       "      <td>обучение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_Bert</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763</td>\n",
       "      <td>тестирование</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name                                              model  time_sec  \\\n",
       "0                                              LogisticRegression()     932.0   \n",
       "0                                                  LGBMClassifier()     704.2   \n",
       "0                                                 RidgeClassifier()      63.9   \n",
       "0         logreg  LogisticRegression(C=10, class_weight='balance...     362.9   \n",
       "1         logreg  LogisticRegression(C=10, class_weight='balance...       0.0   \n",
       "0  logistic_Bert                               LogisticRegression()       0.7   \n",
       "1  logistic_Bert                               LogisticRegression()       0.0   \n",
       "\n",
       "      F1         process  \n",
       "0  0.773  кроссвалидация  \n",
       "0  0.759  кроссвалидация  \n",
       "0  0.704  кроссвалидация  \n",
       "0  0.969        обучение  \n",
       "1  0.774    тестирование  \n",
       "0  0.824        обучение  \n",
       "1  0.763    тестирование  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты модели Bert по метрикам качества на обучении и тестировании ниже, чем у логистической регрессии, однако, стоит отметить, что качество данной модели можно повысить увеличением обучающей выборки, но для этого требуется больший объем оперативной памяти. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В совокупности показателей на обучении и тестировании лучшей является модель:\n",
    "- **logreg = LogisticRegression(C=10, class_weight='balanced', n_jobs=-1, penalty='l1', random_state=123, solver='saga')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mРезультаты выбранной модели\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>F1</th>\n",
       "      <th>process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>LogisticRegression(C=10, class_weight='balance...</td>\n",
       "      <td>362.9</td>\n",
       "      <td>0.969</td>\n",
       "      <td>обучение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logreg</td>\n",
       "      <td>LogisticRegression(C=10, class_weight='balance...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>тестирование</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name                                              model  time_sec  \\\n",
       "0     logreg  LogisticRegression(C=10, class_weight='balance...     362.9   \n",
       "1     logreg  LogisticRegression(C=10, class_weight='balance...       0.0   \n",
       "\n",
       "      F1       process  \n",
       "0  0.969      обучение  \n",
       "1  0.774  тестирование  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1m\" + \"Результаты выбранной модели\" + \"\\033[0;0m\")\n",
    "result_tbl.loc[result_tbl.model_name == 'logreg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе проекта были исследованы данные с комментариями клиентов интернет-магазина к описанию товаров с разметкой о токсичности с целью построения модели для классификации комментариев на позитивные и негативные.\n",
    "\n",
    "На этапе **подготовки данных** было установлено, что в данных присутсвует дисбаланс: соотношение токсичных комментариев к нетоксичным составляет 1:9. Также на этом этапе была разработана функция, которая формирует подвыборку данных, проводит очистку текста от несловесных символов, одиночных символов, лишних пробелов и т.д., лемматтизирует текст, создает матрицу tfidf со словами и их оценками.\n",
    "\n",
    "В **п. 2** с помощью GridSearchCV на кроссвалидации были подобраны гиперпараметры для трех моделей: **LogisticRegression(), LGBMClassifier(), RidgeClassifier()**. В качестве обучающих данных была использована матрица tfidf для 100 000 комментариев из исходных данных. Наилучшие результаты метрики качества показала модель логистической регрессии со значением **F1=0,77**. В **п. 3** данная модель была протестирована.\n",
    "\n",
    "В **п. 4** была исследована модель Bert, которая показала результаты ниже, чем логистическая регрессия, однако для ее обучения потребовалось меньше данных - было использовано 6000 комментариев из исходных данных.\n",
    "\n",
    "В совокупности показателей на обучении и тестировании лучшей была выбрана модель **logreg = LogisticRegression(C=10, class_weight='balanced', n_jobs=-1, penalty='l1', random_state=123, solver='saga')**:\n",
    "- F1 на обучающей выборке - 0,97\n",
    "- F1 на тестовой выборке - 0,77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
